{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "159b3f5d-036f-4848-a96d-cfccf3f38f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e52bb6f0-e549-4b33-8e62-871a3653123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load config\n",
    "with open(\"../experiments/exp4/config.json\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "original_dir = config[\"original_dir\"]\n",
    "cartoon_dir = config[\"cartoon_dir\"]\n",
    "val_original_dir = config[\"val_original_dir\"]\n",
    "val_cartoon_dir = config[\"val_cartoon_dir\"]\n",
    "batch_size = config[\"batch_size\"]\n",
    "total_epochs = config[\"total_epochs\"]\n",
    "lambda_l1 = config[\"lambda_l1\"]\n",
    "learning_rate = config[\"learning_rate\"]\n",
    "limit = config[\"limit\"]\n",
    "beta1, beta2 = config[\"beta1\"], config[\"beta2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba1f4918-e947-4508-a04d-180e1e50fef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66a90756-44f2-48b0-a0ad-580bdc7fc7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class CartoonDataset(Dataset):\n",
    "    def __init__(self, original_dir, cartoon_dir, transform=None, limit=None):\n",
    "        self.original_paths = sorted(glob(os.path.join(original_dir, \"*.png\")))\n",
    "        self.cartoon_paths = sorted(glob(os.path.join(cartoon_dir, \"*.png\")))\n",
    "        if limit:\n",
    "            self.original_paths = self.original_paths[:limit]\n",
    "            self.cartoon_paths = self.cartoon_paths[:limit]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.original_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real = Image.open(self.original_paths[idx]).convert(\"RGB\")\n",
    "        cartoon = Image.open(self.cartoon_paths[idx]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            real = self.transform(real)\n",
    "            cartoon = self.transform(cartoon)\n",
    "        return real, cartoon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c953cd48-0102-4b48-877b-11da847d3822",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd156c03-4603-473f-a687-384388836275",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(CartoonDataset(original_dir, cartoon_dir, transform, limit), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(CartoonDataset(val_original_dir, val_cartoon_dir, transform, limit), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c2fccc7-e69d-447c-b833-c1917620daad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1), nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU()\n",
    "        )\n",
    "        self.middle = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 4, 2, 1), nn.BatchNorm2d(512), nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, 4, 2, 1), nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.middle(self.encoder(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54b865bc-328d-461a-a3ca-9ba518315db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(256, 1, 4, 1, 1), nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "953f2bae-1423-4c07-b147-7af737c96cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=learning_rate, betas=(beta1, beta2))\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(beta1, beta2))\n",
    "adversarial_loss = nn.BCELoss()\n",
    "content_loss = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b25ee10-0b38-40a8-99b2-469e5abdd949",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "g_losses, d_losses, d_accuracies = [], [], []\n",
    "val_g_losses, val_d_losses, val_accuracies = [], [], []\n",
    "start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb6b2768-2dbf-40fc-9803-cd30d7954f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([4, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n",
      "fake: torch.Size([8, 3, 256, 256])\n",
      "disc(fake): torch.Size([8, 1, 31, 31])\n",
      "real_labels: torch.Size([8, 1, 31, 31])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 66\u001b[39m\n\u001b[32m     64\u001b[39m pred_real = (d_real.mean(dim=[\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m]) > \u001b[32m0.5\u001b[39m).float()\n\u001b[32m     65\u001b[39m pred_fake = (d_fake.mean(dim=[\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m]) < \u001b[32m0.5\u001b[39m).float()\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m val_correct += \u001b[43mpred_real\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m + pred_fake.sum().item()\n\u001b[32m     67\u001b[39m val_total += pred_real.numel() + pred_fake.numel()\n\u001b[32m     69\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mfake:\u001b[39m\u001b[33m\"\u001b[39m, fake.shape)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(start_epoch, start_epoch + 10):\n",
    "    start_time = time.time() \n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    g_epoch_loss = 0\n",
    "    d_epoch_loss = 0\n",
    "    accuracy_accum = 0\n",
    "    batch_count = 0\n",
    "\n",
    "    for real, cartoon in train_loader:\n",
    "        real, cartoon = real.to(device), cartoon.to(device)\n",
    "\n",
    "        # Discriminator\n",
    "        fake = generator(real).detach()\n",
    "        d_real = discriminator(cartoon)\n",
    "        d_fake = discriminator(fake)\n",
    "        real_labels = torch.ones_like(d_real)\n",
    "        fake_labels = torch.zeros_like(d_fake)\n",
    "        d_loss = 0.5 * (adversarial_loss(d_real, real_labels) + adversarial_loss(d_fake, fake_labels))\n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        # Accuracy\n",
    "        pred_real = (d_real.mean(dim=[1, 2, 3]) > 0.5).float()\n",
    "        pred_fake = (d_fake.mean(dim=[1, 2, 3]) < 0.5).float()\n",
    "        correct = pred_real.sum().item() + pred_fake.sum().item()\n",
    "        accuracy_accum += correct / (pred_real.numel() + pred_fake.numel())\n",
    "        batch_count += 1\n",
    "\n",
    "        # Generator\n",
    "        fake = generator(real)\n",
    "        g_adv = adversarial_loss(discriminator(fake), real_labels)\n",
    "        g_l1 = content_loss(fake, cartoon)\n",
    "        g_loss = g_adv + lambda_l1 * g_l1\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        g_epoch_loss += g_loss.item()\n",
    "        d_epoch_loss += d_loss.item()\n",
    "\n",
    "    # Logging\n",
    "    g_losses.append(g_epoch_loss / len(train_loader))\n",
    "    d_losses.append(d_epoch_loss / len(train_loader))\n",
    "    d_accuracies.append(accuracy_accum / batch_count)\n",
    "\n",
    "    # ✅ Validation Accuracy\n",
    "    generator.eval()\n",
    "    discriminator.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_g_loss_total = 0\n",
    "    val_d_loss_total = 0\n",
    "    with torch.no_grad():\n",
    "        for real, cartoon in val_loader:\n",
    "            real, cartoon = real.to(device), cartoon.to(device)\n",
    "\n",
    "            fake = generator(real)\n",
    "            d_real = discriminator(cartoon)\n",
    "            d_fake = discriminator(fake)\n",
    "            \n",
    "            pred_real = (d_real.mean(dim=[1, 2, 3]) > 0.5).float()\n",
    "            pred_fake = (d_fake.mean(dim=[1, 2, 3]) < 0.5).float()\n",
    "            val_correct += pred_real.sum().item() + pred_fake.sum().item()\n",
    "            val_total += pred_real.numel() + pred_fake.numel()\n",
    "\n",
    "            # print(\"fake:\", fake.shape)\n",
    "            # print(\"disc(fake):\", discriminator(fake).shape)\n",
    "            # print(\"real_labels:\", real_labels.shape)\n",
    "             # Validation losses\n",
    "            real_labels = torch.ones_like(d_real)\n",
    "            fake_labels = torch.zeros_like(d_fake)\n",
    "            d_loss_real = adversarial_loss(d_real, real_labels)\n",
    "            d_loss_fake = adversarial_loss(d_fake, fake_labels)\n",
    "            d_loss = (d_loss_real + d_loss_fake) * 0.5\n",
    "            val_d_loss_total += d_loss.item()\n",
    "\n",
    "            g_adv = adversarial_loss(discriminator(fake), real_labels)\n",
    "            g_l1 = content_loss(fake, cartoon)\n",
    "            g_loss = g_adv + lambda_l1 * g_l1\n",
    "            val_g_loss_total += g_loss.item()\n",
    "            \n",
    "\n",
    "    val_acc = val_correct / val_total\n",
    "    val_accuracies.append(val_acc)\n",
    "    val_g_losses.append(val_g_loss_total / len(val_loader))\n",
    "    val_d_losses.append(val_d_loss_total / len(val_loader))\n",
    "\n",
    "    # ✅ Confusion Matrix\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        all_labels, all_preds = [], []\n",
    "        with torch.no_grad():\n",
    "            for real, cartoon in val_loader:\n",
    "                real, cartoon = real.to(device), cartoon.to(device)\n",
    "                d_real = discriminator(cartoon)\n",
    "                d_fake = discriminator(generator(real))\n",
    "                preds_real = (d_real.mean(dim=[1, 2, 3]) > 0.5).int().cpu().numpy()\n",
    "                preds_fake = (d_fake.mean(dim=[1, 2, 3]) > 0.5).int().cpu().numpy()\n",
    "                labels_real = torch.ones_like(d_real.mean(dim=[1, 2, 3])).int().cpu().numpy()\n",
    "                labels_fake = torch.zeros_like(d_fake.mean(dim=[1, 2, 3])).int().cpu().numpy()\n",
    "                all_preds.extend(preds_real)\n",
    "                all_preds.extend(preds_fake)\n",
    "                all_labels.extend(labels_real)\n",
    "                all_labels.extend(labels_fake)\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        cm_df = pd.DataFrame(cm, index=[\"Fake\", \"Real\"], columns=[\"Pred Fake\", \"Pred Real\"])\n",
    "        cm_df.to_csv(f\"../experiments/exp4/logs/confusion_epoch_{epoch+1}.csv\")\n",
    "\n",
    "    end_time = time.time()  # ⏱️ End timer\n",
    "    epoch_time = end_time - start_time \n",
    "    \n",
    "    print(\n",
    "    f\"Epoch {epoch+1} | \"\n",
    "    f\"Train G Loss: {g_losses[-1]:.4f} | \"\n",
    "    f\"Train D Loss: {d_losses[-1]:.4f} | \"\n",
    "    f\"Train Acc: {d_accuracies[-1]:.4f} | \"\n",
    "    f\"Val G Loss: {val_g_losses[-1]:.4f} | \"\n",
    "    f\"Val D Loss: {val_d_losses[-1]:.4f} | \"\n",
    "    f\"Val Acc: {val_accuracies[-1]:.4f} | \"\n",
    "    f\"Time: {epoch_time:.2f}s\"\n",
    ")\n",
    "    # Save losses\n",
    "    with open(\"../experiments/exp4/losses/losses.json\", \"w\") as f:\n",
    "        json.dump({\n",
    "            \"g_losses\": g_losses,\n",
    "            \"d_losses\": d_losses,\n",
    "            \"d_accuracies\": d_accuracies,\n",
    "            \"val_g_losses\" : val_g_losses,\n",
    "            \"val_d_losses\" : val_d_losses,\n",
    "            \"val_accuracies\": val_accuracies\n",
    "        }, f)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save({\n",
    "            'generator': generator.state_dict(),\n",
    "            'discriminator': discriminator.state_dict(),\n",
    "            'g_optimizer': g_optimizer.state_dict(),\n",
    "            'd_optimizer': d_optimizer.state_dict(),\n",
    "            'epoch': epoch + 1\n",
    "        }, f\"../experiments/exp4/checkpoints/cartoongan_epoch{epoch+1}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa069884-eb2e-4278-a2a0-9e774ceba6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
